{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    254901\n",
       "1    149257\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/input/train.csv', index_col='id')\n",
    "\n",
    "train_df['question1'].fillna('', inplace=True)\n",
    "train_df['question2'].fillna('', inplace=True)\n",
    "\n",
    "# filter out question shorter than 10 characters\n",
    "train_df['q1_len'] = train_df['question1'].str.len()\n",
    "train_df['q2_len'] = train_df['question2'].str.len()\n",
    "\n",
    "train_df = train_df.loc[lambda df: (df['q1_len'] > 10) & (df['q2_len'] > 10)]\n",
    "\n",
    "# subset data\n",
    "#train_df = train_df.loc[0:199999]\n",
    "\n",
    "train_df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['q1_len'] = train_df['question1'].str.len()\n",
    "train_df['q2_len'] = train_df['question2'].str.len()\n",
    "\n",
    "train_df['len_diff'] = abs(train_df['q1_len'] - train_df['q2_len'])\n",
    "\n",
    "train_df['q1_n_words'] = train_df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "train_df['q2_n_words'] = train_df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "\n",
    "train_df['n_word_diff'] = abs(train_df['q1_n_words'] - train_df['q2_n_words'])\n",
    "\n",
    "train_df['q1_mean_word_len'] = train_df['question1'].apply(lambda row: np.mean([len(i) for i in row.split(\" \")]))\n",
    "train_df['q2_mean_word_len'] = train_df['question2'].apply(lambda row: np.mean([len(i) for i in row.split(\" \")]))\n",
    "\n",
    "train_df['mean_word_len_diff'] = abs(train_df['q1_mean_word_len'] - train_df['q2_mean_word_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "On length, word count, and words shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalized_word_share(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * len(w1 & w2)/(len(w1 | w2))\n",
    "\n",
    "train_df['word_share'] = train_df.apply(normalized_word_share, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323326, 15)\n",
      "(80832, 15)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(train_df, \n",
    "                                  test_size=0.2, random_state=42, \n",
    "                                  stratify=train_df['is_duplicate'].values)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train.loc[:, ['len_diff', 'n_word_diff', 'word_share']].values, X_train['is_duplicate'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.02459190113\n",
      "8.92781599603\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict_proba(X_val.loc[:, ['len_diff', 'n_word_diff', 'word_share']].values)\n",
    "\n",
    "print(log_loss(X_val['is_duplicate'].values, pred[:, 0]))\n",
    "print(log_loss(X_val['is_duplicate'].values, [0.999999 if i >= 0.5 else 0.000001 for i in pred[:, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('../models/logistic_regression.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = pickle.load(open('../models/logistic_regression.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
